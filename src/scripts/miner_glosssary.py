"""
Este script vai ler as √∫ltimas p√°ginas do PDF (onde geralmente est√° o √≠ndice), 
extrair os termos e salv√°-los na tabela theological_concepts.

Nota: Voc√™ precisar√° abrir o PDF manualmente uma vez para ver 
em qual p√°gina come√ßa o "General Index" (digamos, p√°gina 900).

Como integrar isso ao fluxo?

    Descubra as P√°ginas: Abra o bhagavad-gita-4ed-eng.pdf. V√° at√© o final. Ache onde come√ßa o "General Index". Anote o n√∫mero da p√°gina (digamos, 1050) e coloque na vari√°vel START_PAGE do script acima.

    Rode o Minerador:
    PowerShell

    py src/scripts/miner_glossary.py

    Resultado: Sua tabela theological_concepts vai pular de 20 termos para 2.000 termos (ex: Abhidheya, Acintya-bhedabheda, Goloka, Gopis...).

    Rode o Gold Washer: Agora, rode novamente o py src/intelligence/gold_washer.py. Como a lista de conceitos agora √© gigante e vinda do pr√≥prio livro, o "tagueamento" das suas aulas e versos ser√° infinitamente mais preciso.

E sobre o "Quoted Verses"?

Para o √≠ndice de versos citados (quoted verses), a l√≥gica √© similar, mas o valor dele √© maior para Valida√ß√£o Cruzada.

Podemos fazer um script futuro que l√™ esse √≠ndice e verifica: "O √≠ndice diz que o verso SB 1.2.11 foi citado na p√°gina 450. Ser√° que nosso minerador de texto encontrou essa cita√ß√£o?"

Mas, por enquanto, focar no General Index vai dar um "c√©rebro" enorme para a sua IA entender o vocabul√°rio Gaudiya.
"""

import pdfplumber
import re
import sqlite3
import os
import sys

# Setup de diret√≥rios
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '..', '..'))
sys.path.append(project_root)

DB_PATH = os.path.join(project_root, "database", "harikatha.db")
PDF_PATH = "bhagavad-gita-4ed-eng.pdf" # Seu arquivo

# CONFIGURE AQUI: Onde come√ßa e termina o √≠ndice no seu PDF?
# (Abra o PDF e olhe o n√∫mero "absoluto" da p√°gina no leitor)
START_PAGE = 1050  # Exemplo: p√°gina onde come√ßa "General Index"
END_PAGE = 1100    # Exemplo: p√°gina final

def save_concepts(concepts):
    conn = sqlite3.connect(DB_PATH)
    count = 0
    try:
        for term in concepts:
            # Limpeza: remove pontos finais, n√∫meros e espa√ßos extras
            clean_term = term.strip().strip('.').strip()
            
            # Pula termos muito curtos ou num√©ricos
            if len(clean_term) < 3 or clean_term.isdigit(): continue
            
            # Tenta categorizar automaticamente (b√°sico)
            category = "General"
            if clean_term[0].isupper(): category = "Proper Noun" # Nomes pr√≥prios
            
            try:
                conn.execute("""
                    INSERT OR IGNORE INTO theological_concepts (term, category) 
                    VALUES (?, ?)
                """, (clean_term, category))
                count += 1
            except sqlite3.Error: pass
            
        conn.commit()
        print(f"‚úÖ {count} novos conceitos adicionados √† Ontologia.")
    finally:
        conn.close()

def mine_index():
    print(f"‚õèÔ∏è  Minerando √çndice do PDF (P√°gs {START_PAGE}-{END_PAGE})...")
    
    found_terms = set()
    
    # Regex para pegar linhas de √≠ndice t√≠picas: "Termo ............ 123, 456"
    # Grupo 1: O Texto
    # Grupo 2: Os Pontinhos (opcional)
    # Grupo 3: Os N√∫meros
    index_pattern = re.compile(r'^([A-Za-zƒÅƒ´≈´·πõ·π≠·∏ç·πá≈õ·π£·πÅ·∏•ƒÄƒ™≈™·πö·π¨·∏å·πÜ≈ö·π¢·πÄ·∏§\s\(\)\-]+?)(?:\.{2,}|,)\s*(\d+.*)$')

    with pdfplumber.open(PDF_PATH) as pdf:
        # Itera apenas nas p√°ginas do √≠ndice
        # pdfplumber usa index 0, ent√£o subtra√≠mos 1
        pages_to_process = pdf.pages[START_PAGE-1 : END_PAGE]
        
        for page in pages_to_process:
            text = page.extract_text()
            if not text: continue
            
            lines = text.split('\n')
            for line in lines:
                match = index_pattern.search(line.strip())
                if match:
                    term = match.group(1)
                    found_terms.add(term)
                    # print(f"   Termo: {term}") # Debug

    print(f"üìö Total de termos brutos encontrados: {len(found_terms)}")
    save_concepts(found_terms)

if __name__ == "__main__":
    mine_index()